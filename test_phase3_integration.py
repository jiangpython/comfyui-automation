#!/usr/bin/env python3
"""
ComfyUI è‡ªåŠ¨åŒ–ç³»ç»Ÿ - ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯•
åŠŸèƒ½ï¼šéªŒè¯ç”»å»ŠåŠŸèƒ½ã€æ•°æ®åˆ†æåŠŸèƒ½å’Œæ¨èå¼•æ“çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
"""

import os
import sys
import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.utils.prompt_analyzer import PromptAnalyzer, AnalysisReport
from src.utils.recommendation_engine import RecommendationEngine
from src.utils.metadata_schema import TaskMetadata


class Phase3IntegrationTest:
    """ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_dir = Path("test_output")
        self.test_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®åº“
        self.test_db_path = self.test_dir / "test_tasks.db"
        self._setup_test_database()
        
        # åˆ›å»ºæµ‹è¯•å…ƒæ•°æ®ç›®å½•
        self.test_metadata_dir = self.test_dir / "metadata"
        self.test_metadata_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®
        self._create_test_data()
        
        print("ğŸ§ª ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯•åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ æµ‹è¯•ç›®å½•: {self.test_dir}")
        print(f"ğŸ—„ï¸ æµ‹è¯•æ•°æ®åº“: {self.test_db_path}")
        print(f"ğŸ“„ æµ‹è¯•å…ƒæ•°æ®ç›®å½•: {self.test_metadata_dir}")
    
    def _setup_test_database(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®åº“"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®åº“
        with sqlite3.connect(self.test_db_path) as conn:
            cursor = conn.cursor()
            
            # åˆ›å»ºä»»åŠ¡è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS tasks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    task_id TEXT UNIQUE NOT NULL,
                    prompt TEXT NOT NULL,
                    status TEXT NOT NULL,
                    created_at TEXT NOT NULL,
                    quality_score REAL,
                    generation_time REAL,
                    error_message TEXT,
                    workflow_params TEXT
                )
            """)
            
            conn.commit()
    
    def _create_test_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        print("ğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®...")
        
        # æµ‹è¯•æç¤ºè¯
        test_prompts = [
            "a beautiful landscape with mountains and lakes, masterpiece, best quality",
            "portrait of a young woman, anime style, high quality",
            "futuristic cityscape at sunset, oil painting, ultra detailed",
            "cute cat sitting on a windowsill, cartoon style, professional",
            "abstract art with vibrant colors, digital art, award winning",
            "steampunk mechanical device, realistic, high resolution",
            "fantasy castle in the clouds, concept art, detailed",
            "minimalist geometric design, clean, sharp focus"
        ]
        
        # ç”Ÿæˆæµ‹è¯•ä»»åŠ¡æ•°æ®
        tasks = []
        for i, prompt in enumerate(test_prompts):
            # ç”Ÿæˆå¤šä¸ªå˜ä½“
            for j in range(3):
                task_id = f"test_task_{i}_{j}"
                status = "completed" if j < 2 else "failed"
                quality_score = 0.6 + (i * 0.05) + (j * 0.1) + (0.1 if status == "completed" else 0)
                quality_score = min(1.0, max(0.0, quality_score))
                
                task = TaskMetadata(
                    task_id=task_id,
                    prompt=prompt,
                    workflow_type="txt2img",
                    status=status,
                    created_at=datetime.now() - timedelta(days=i*2, hours=j*3),
                    quality_score=quality_score if status == "completed" else None,
                    actual_time=10 + i * 2 + j * 3,
                    error_message="timeout error" if status == "failed" else None
                )
                tasks.append(task)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        with sqlite3.connect(self.test_db_path) as conn:
            cursor = conn.cursor()
            
            for task in tasks:
                cursor.execute("""
                    INSERT OR REPLACE INTO tasks 
                    (task_id, prompt, status, created_at, quality_score, generation_time, error_message)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    task.task_id,
                    task.prompt,
                    task.status,
                    task.created_at.isoformat(),
                    task.quality_score,
                    task.actual_time,
                    task.error_message
                ))
            
            conn.commit()
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        for i, task in enumerate(tasks):
            json_file = self.test_metadata_dir / f"task_{i:03d}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'task_id': task.task_id,
                    'prompt': task.prompt,
                    'status': task.status,
                    'created_at': task.created_at.isoformat(),
                    'quality_score': task.quality_score,
                    'generation_time': task.actual_time,
                    'error_message': task.error_message
                }, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åˆ›å»ºäº† {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡")
    
    def test_prompt_analyzer(self):
        """æµ‹è¯•æç¤ºè¯åˆ†æå™¨"""
        print("\nğŸ” æµ‹è¯•æç¤ºè¯åˆ†æå™¨...")
        
        try:
            # åˆå§‹åŒ–åˆ†æå™¨
            analyzer = PromptAnalyzer(str(self.test_db_path))
            
            # æµ‹è¯•å•ä¸ªæç¤ºè¯åˆ†æ
            test_prompt = "a beautiful landscape with mountains and lakes, masterpiece, best quality"
            analysis = analyzer.analyze_prompt_performance(test_prompt, days_back=30)
            
            print(f"  ğŸ“ æµ‹è¯•æç¤ºè¯: {test_prompt}")
            print(f"  ğŸ“Š æˆåŠŸç‡: {analysis.success_rate:.2%}")
            print(f"  â­ å¹³å‡è´¨é‡: {analysis.avg_quality:.2f}")
            print(f"  â±ï¸ å¹³å‡ç”Ÿæˆæ—¶é—´: {analysis.avg_generation_time:.1f}s")
            print(f"  ğŸ¯ æ•ˆæœè¯„åˆ†: {analysis.effectiveness_score:.2f}")
            
            # æµ‹è¯•å…ƒç´ æ•ˆæœåˆ†æ
            element_analysis = analyzer.analyze_element_effectiveness(days_back=30)
            print(f"  ğŸ§© åˆ†æå…ƒç´ æ•°é‡: {len(element_analysis)}")
            
            if element_analysis:
                best_element = element_analysis[0]
                print(f"  ğŸ† æœ€ä½³å…ƒç´ : {best_element.element} (æˆåŠŸç‡: {best_element.success_rate:.2%})")
            
            # æµ‹è¯•å®Œæ•´åˆ†ææŠ¥å‘Š
            report = analyzer.generate_analysis_report(days_back=30)
            print(f"  ğŸ“ˆ æ€»ä»»åŠ¡æ•°: {report.total_tasks}")
            print(f"  âœ… æˆåŠŸç‡: {report.overall_success_rate:.2%}")
            print(f"  ğŸ’¡ å»ºè®®æ•°é‡: {len(report.recommendations)}")
            
            # å¯¼å‡ºæŠ¥å‘Š
            report_path = self.test_dir / "analysis_report.json"
            analyzer.export_analysis_report(report, str(report_path))
            print(f"  ğŸ’¾ æŠ¥å‘Šå·²å¯¼å‡º: {report_path}")
            
            print("  âœ… æç¤ºè¯åˆ†æå™¨æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"  âŒ æç¤ºè¯åˆ†æå™¨æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_recommendation_engine(self):
        """æµ‹è¯•æ¨èå¼•æ“"""
        print("\nğŸ¤– æµ‹è¯•æ¨èå¼•æ“...")
        
        try:
            # åˆå§‹åŒ–æ¨èå¼•æ“
            engine = RecommendationEngine(str(self.test_db_path))
            
            # æµ‹è¯•æç¤ºè¯ä¼˜åŒ–æ¨è
            test_prompt = "a beautiful landscape with mountains"
            optimization = engine.recommend_prompt_optimization(test_prompt)
            
            print(f"  ğŸ“ åŸå§‹æç¤ºè¯: {optimization.original_prompt}")
            print(f"  âœ¨ æ¨èæç¤ºè¯: {optimization.recommended_prompt}")
            print(f"  ğŸ¯ ç½®ä¿¡åº¦: {optimization.confidence_score:.2f}")
            print(f"  ğŸ“ˆ é¢„æœŸè´¨é‡æå‡: {optimization.expected_quality_boost:.2f}")
            print(f"  ğŸ’­ æ¨ç†: {optimization.reasoning}")
            
            # æµ‹è¯•å…ƒç´ æ¨è
            element_recommendations = engine.recommend_element_combinations(test_prompt, max_elements=3)
            print(f"  ğŸ§© å…ƒç´ æ¨èæ•°é‡: {len(element_recommendations)}")
            
            for i, rec in enumerate(element_recommendations[:3]):
                print(f"    {i+1}. {rec.element} ({rec.recommendation_type}) - ç½®ä¿¡åº¦: {rec.confidence:.2f}")
            
            # æµ‹è¯•å·¥ä½œæµå‚æ•°æ¨è
            test_params = {'cfg_scale': 7.0, 'steps': 20}
            param_recommendations = engine.recommend_workflow_parameters(test_params, 'quality')
            print(f"  âš™ï¸ å‚æ•°æ¨èæ•°é‡: {len(param_recommendations)}")
            
            for rec in param_recommendations:
                print(f"    - {rec.parameter_name}: {rec.current_value} â†’ {rec.recommended_value}")
            
            # æµ‹è¯•æ‰¹é‡ç­–ç•¥æ¨è
            test_prompts = ["a beautiful landscape", "portrait of a woman", "abstract art"]
            batch_recommendations = engine.recommend_batch_strategies(test_prompts, 'optimization')
            print(f"  ğŸ“¦ æ‰¹é‡ç­–ç•¥æ¨èæ•°é‡: {len(batch_recommendations)}")
            
            # æµ‹è¯•æ™ºèƒ½å»ºè®®
            context = {'low_success_rate': True, 'quality_issues': True}
            suggestions = engine.generate_smart_suggestions(context)
            print(f"  ğŸ’¡ æ™ºèƒ½å»ºè®®æ•°é‡: {len(suggestions)}")
            
            print("  âœ… æ¨èå¼•æ“æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"  âŒ æ¨èå¼•æ“æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_gallery_files(self):
        """æµ‹è¯•ç”»å»Šæ–‡ä»¶"""
        print("\nğŸ–¼ï¸ æµ‹è¯•ç”»å»Šæ–‡ä»¶...")
        
        try:
            # æ£€æŸ¥HTMLæ–‡ä»¶
            html_file = Path("templates/gallery.html")
            if html_file.exists():
                with open(html_file, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                # æ£€æŸ¥å…³é”®å…ƒç´ 
                required_elements = [
                    'gallery-grid', 'searchInput', 'imageModal', 'starRating',
                    'selectAllBtn', 'exportSelectedBtn', 'gallery.js'
                ]
                
                missing_elements = []
                for element in required_elements:
                    if element not in html_content:
                        missing_elements.append(element)
                
                if missing_elements:
                    print(f"  âš ï¸ HTMLæ–‡ä»¶ç¼ºå°‘å…ƒç´ : {missing_elements}")
                else:
                    print("  âœ… HTMLæ–‡ä»¶ç»“æ„å®Œæ•´")
            else:
                print("  âŒ HTMLæ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥CSSæ–‡ä»¶
            css_file = Path("static/css/gallery.css")
            if css_file.exists():
                with open(css_file, 'r', encoding='utf-8') as f:
                    css_content = f.read()
                
                # æ£€æŸ¥å…³é”®æ ·å¼
                required_styles = [
                    'gallery-grid', 'image-card', 'modal', 'sidebar',
                    'btn-primary', 'star-rating', 'quality-badge'
                ]
                
                missing_styles = []
                for style in required_styles:
                    if style not in css_content:
                        missing_styles.append(style)
                
                if missing_styles:
                    print(f"  âš ï¸ CSSæ–‡ä»¶ç¼ºå°‘æ ·å¼: {missing_styles}")
                else:
                    print("  âœ… CSSæ–‡ä»¶æ ·å¼å®Œæ•´")
            else:
                print("  âŒ CSSæ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥JavaScriptæ–‡ä»¶
            js_file = Path("static/js/gallery.js")
            if js_file.exists():
                with open(js_file, 'r', encoding='utf-8') as f:
                    js_content = f.read()
                
                # æ£€æŸ¥å…³é”®åŠŸèƒ½
                required_functions = [
                    'GalleryManager', 'loadImages', 'applyFilters',
                    'openModal', 'toggleSelection', 'exportSelected'
                ]
                
                missing_functions = []
                for func in required_functions:
                    if func not in js_content:
                        missing_functions.append(func)
                
                if missing_functions:
                    print(f"  âš ï¸ JavaScriptæ–‡ä»¶ç¼ºå°‘åŠŸèƒ½: {missing_functions}")
                else:
                    print("  âœ… JavaScriptæ–‡ä»¶åŠŸèƒ½å®Œæ•´")
            else:
                print("  âŒ JavaScriptæ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            print("  âœ… ç”»å»Šæ–‡ä»¶æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"  âŒ ç”»å»Šæ–‡ä»¶æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_data_integration(self):
        """æµ‹è¯•æ•°æ®é›†æˆ"""
        print("\nğŸ”— æµ‹è¯•æ•°æ®é›†æˆ...")
        
        try:
            # æµ‹è¯•æ•°æ®åº“è¿æ¥
            with sqlite3.connect(self.test_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM tasks")
                task_count = cursor.fetchone()[0]
                print(f"  ğŸ“Š æ•°æ®åº“ä»»åŠ¡æ•°é‡: {task_count}")
            
            # æµ‹è¯•JSONæ–‡ä»¶
            json_files = list(self.test_metadata_dir.glob("*.json"))
            print(f"  ğŸ“„ JSONæ–‡ä»¶æ•°é‡: {len(json_files)}")
            
            # æµ‹è¯•æ•°æ®ä¸€è‡´æ€§
            db_tasks = []
            with sqlite3.connect(self.test_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT task_id, prompt, status FROM tasks")
                db_tasks = cursor.fetchall()
            
            json_tasks = []
            for json_file in json_files:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    json_tasks.append((data['task_id'], data['prompt'], data['status']))
            
            print(f"  ğŸ”„ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥: æ•°æ®åº“ {len(db_tasks)} æ¡ï¼ŒJSON {len(json_tasks)} æ¡")
            
            # æµ‹è¯•åˆ†æå™¨å’Œæ¨èå¼•æ“çš„æ•°æ®è®¿é—®
            analyzer = PromptAnalyzer(str(self.test_db_path))
            engine = RecommendationEngine(str(self.test_db_path))
            
            # æµ‹è¯•æ•°æ®æŸ¥è¯¢
            recent_tasks = analyzer._get_recent_tasks(30)
            print(f"  ğŸ“ˆ åˆ†æå™¨å¯è®¿é—®ä»»åŠ¡æ•°: {len(recent_tasks)}")
            
            print("  âœ… æ•°æ®é›†æˆæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"  âŒ æ•°æ®é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_end_to_end_workflow(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        print("\nğŸ”„ æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ...")
        
        try:
            # 1. æ•°æ®åˆ†æ
            analyzer = PromptAnalyzer(str(self.test_db_path))
            report = analyzer.generate_analysis_report(days_back=30)
            
            # 2. åŸºäºåˆ†æç»“æœç”Ÿæˆæ¨è
            engine = RecommendationEngine(str(self.test_db_path))
            
            # é€‰æ‹©æ•ˆæœæœ€å¥½çš„æç¤ºè¯è¿›è¡Œä¼˜åŒ–
            if report.top_performing_prompts:
                best_prompt = report.top_performing_prompts[0]
                optimization = engine.recommend_prompt_optimization(best_prompt.prompt)
                
                print(f"  ğŸ† æœ€ä½³æç¤ºè¯: {best_prompt.prompt}")
                print(f"  âœ¨ ä¼˜åŒ–å»ºè®®: {optimization.recommended_prompt}")
                print(f"  ğŸ“ˆ é¢„æœŸæå‡: {optimization.expected_quality_boost:.2f}")
            
            # 3. ç”Ÿæˆæ‰¹é‡ç­–ç•¥
            test_prompts = [p.prompt for p in report.top_performing_prompts[:3]]
            batch_strategies = engine.recommend_batch_strategies(test_prompts, 'optimization')
            
            print(f"  ğŸ“¦ æ‰¹é‡ç­–ç•¥æ•°é‡: {len(batch_strategies)}")
            
            # 4. ç”Ÿæˆæ™ºèƒ½å»ºè®®
            context = {
                'low_success_rate': report.overall_success_rate < 0.8,
                'quality_issues': report.avg_quality_score < 0.7
            }
            suggestions = engine.generate_smart_suggestions(context)
            
            print(f"  ğŸ’¡ æ™ºèƒ½å»ºè®®: {len(suggestions)} æ¡")
            for i, suggestion in enumerate(suggestions[:3]):
                print(f"    {i+1}. {suggestion}")
            
            print("  âœ… ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"  âŒ ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯•")
        print("=" * 50)
        
        test_results = []
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_results.append(("ç”»å»Šæ–‡ä»¶æµ‹è¯•", self.test_gallery_files()))
        test_results.append(("æ•°æ®é›†æˆæµ‹è¯•", self.test_data_integration()))
        test_results.append(("æç¤ºè¯åˆ†æå™¨æµ‹è¯•", self.test_prompt_analyzer()))
        test_results.append(("æ¨èå¼•æ“æµ‹è¯•", self.test_recommendation_engine()))
        test_results.append(("ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•", self.test_end_to_end_workflow()))
        
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        print("\n" + "=" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 50)
        
        passed = 0
        total = len(test_results)
        
        for test_name, result in test_results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test_name}: {status}")
            if result:
                passed += 1
        
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
        
        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¬¬ä¸‰é˜¶æ®µåŠŸèƒ½å®Œæ•´å¯ç”¨")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        
        return passed == total
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
        if self.test_dir.exists():
            shutil.rmtree(self.test_dir)
            print(f"ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶: {self.test_dir}")


def main():
    """ä¸»å‡½æ•°"""
    test = Phase3IntegrationTest()
    
    try:
        success = test.run_all_tests()
        return 0 if success else 1
    finally:
        # è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶
        response = input("\næ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
        if response in ['y', 'yes']:
            test.cleanup()
        else:
            print(f"æµ‹è¯•æ–‡ä»¶ä¿ç•™åœ¨: {test.test_dir}")


if __name__ == "__main__":
    exit(main())
